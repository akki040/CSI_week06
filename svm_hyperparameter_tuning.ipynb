{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d2fc6c1-61d7-46ef-aefc-3b9821329e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome to the Hyperparameter Tuning Project!\n",
      "We will use the Wine dataset and tune an SVM model.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "print(\" Welcome to the Hyperparameter Tuning Project!\")\n",
    "print(\"We will use the Wine dataset and tune an SVM model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd10fa81-1906-4eff-b877-6d426b7b94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the Wine dataset (already in sklearn)\n",
    "wine = datasets.load_wine()\n",
    "X = wine.data\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acbb178a-b2a4-435a-8133-0134cc7ce883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data into training and test sets (80% train, 20% test)...\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Split data into training and testing sets\n",
    "print(\"\\nSplitting data into training and test sets (80% train, 20% test)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2ecc036-5192-4841-b68d-65b4573b24c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose hyperparameter tuning method ('grid' or 'random'):  random\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Ask user which hyperparameter tuning method to use\n",
    "method = input(\"\\nChoose hyperparameter tuning method ('grid' or 'random'): \").strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe17be1b-460f-474c-879e-bb28a19357cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the hyperparameter options\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': [0.1, 1, 'scale', 'auto']\n",
    "}\n",
    "\n",
    "param_dist = {\n",
    "    'C': uniform(0.1, 10),  # Uniform distribution between 0.1 and 10\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 10))  # Wide range of gamma values\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c739624d-b7e9-4822-a751-023e732bddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter number of iterations for RandomizedSearchCV (e.g., 20):  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Running RandomizedSearchCV with 15 iterations and parameters:\n",
      "{'C': 'uniform distribution between 0.1 and 10', 'kernel': ['linear', 'rbf', 'poly'], 'gamma': 'scale, auto, and values from 0.001 to 1000 (log scale)'}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Run hyperparameter tuning based on user choice\n",
    "if method == 'grid':\n",
    "    print(\"\\n Running GridSearchCV with these parameters:\")\n",
    "    print(param_grid)\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=SVC(), param_grid=param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "elif method == 'random':\n",
    "    try:\n",
    "        n_iter = int(input(\"\\nEnter number of iterations for RandomizedSearchCV (e.g., 20): \"))\n",
    "    except:\n",
    "        n_iter = 20\n",
    "        print(\"Invalid input. Defaulting to 20 iterations.\")\n",
    "    \n",
    "    print(f\"\\n Running RandomizedSearchCV with {n_iter} iterations and parameters:\")\n",
    "    print({\n",
    "        'C': \"uniform distribution between 0.1 and 10\",\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': 'scale, auto, and values from 0.001 to 1000 (log scale)'\n",
    "    })\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=SVC(), \n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=5,\n",
    "        random_state=24\n",
    "    )\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "else:\n",
    "    print(\"\\n Invalid method selected. Please restart and choose either 'grid' or 'random'.\")\n",
    "    best_model = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24628074-feb8-42f6-8045-cbc2e1d423ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model found!\n",
      "\n",
      " Model Evaluation Metrics:\n",
      "Best Hyperparameters: {'C': 4.649739870636131, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy : 0.9444\n",
      "Precision: 0.9407\n",
      "Recall   : 0.9524\n",
      "F1 Score : 0.9433\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.86      0.92        14\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.95      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the best model (if tuning was successful)\n",
    "if best_model:\n",
    "    print(\"\\n Best model found!\")\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    print(\"\\n Model Evaluation Metrics:\")\n",
    "    print(f\"Best Hyperparameters: {best_params}\")\n",
    "    print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "    print(f\"Recall   : {recall_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "    print(f\"F1 Score : {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "    \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3d72e-83fe-4945-8fcc-0606943cc3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
